{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Engineer Interview Questions with Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Why does one use MSE as a measure of quality. What is the scientific/mathematical reason for the same?\n",
    "#### Answer\n",
    "Mean Squared Error (MSE) is a widely used measure of quality in statistics and machine learning due to its solid mathematical foundation. It quantifies the variance and average squared distance between predicted values and actual values, providing a clear and interpretable metric of model performance. The squaring of errors in MSE penalizes larger errors more than smaller ones, which can be particularly useful in emphasizing the importance of avoiding large deviations in predictions. Mathematically, MSE is differentiable, which facilitates finding optimal solutions through gradient descent and other optimization techniques common in machine learning. Lastly, MSE relates directly to the variance and bias of an estimator, providing insights into the error characteristics of a model, which are crucial for understanding and improving model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: How would you code up a custom rectangle detector?\n",
    "#### Answer\n",
    "To code a custom rectangle detector, you could use a combination of image processing techniques and machine learning algorithms. Start by preprocessing the image using techniques like grayscale conversion and edge detection (e.g., using the Canny edge detector) to highlight potential boundaries of rectangles. Apply contour detection methods (such as those available in OpenCV) to find closed contours in the image. For each detected contour, check if it can be approximated by a polygon with four vertices using a function like cv2.approxPolyDP(); this helps in identifying shapes that closely resemble rectangles. Finally, verify the properties of these polygons, such as ensuring the angles are close to 90 degrees and opposite sides are parallel, to confirm they are rectangles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: What is Back-propagation?\n",
    "#### Answer\n",
    "Back-propagation is an algorithm used for training artificial neural networks. It calculates the gradient of the loss function with respect to each weight in the network by applying the chain rule, moving backwards from the output to the input layer. This process updates the weights to minimize the loss, allowing the network to learn from the data. Back-propagation is essential for deep learning models as it efficiently handles weight adjustments throughout multiple layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Explain Overfit vs Underfit\n",
    "#### Answer\n",
    "Overfitting occurs when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means the model is too complex, with too many parameters relative to the number of observations. Underfitting occurs when a model is too simple, both unable to model the underlying data well and to generalize to new data. This often happens if the model has too few parameters to capture underlying trends in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Closed form solution to linear regression?\n",
    "#### Answer\n",
    "The closed form solution to linear regression is known as the Normal Equation. It provides a way to find the best fitting line to a set of points by minimizing the sum of the squared differences between observed and predicted values. Mathematically, it can be expressed as: Œ≤=(X^TX)^‚àí1X^Ty where ùëã is the matrix of input features, y is the vector of target values, and Œ≤ are the parameters of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Explain Vanishing Gradient vs Exploding Gradients due to choice of ReLU vs Sigmoid\n",
    "#### Answer\n",
    "Vanishing Gradients: This problem often occurs with the sigmoid activation function, especially in deep networks. As the absolute value of the input increases, the gradient of the sigmoid function approaches zero, which results in gradients that are too small for effective learning in the lower layers of the network during back-propagation.\n",
    "Exploding Gradients: This is more common with ReLU (Rectified Linear Unit) in very deep networks because the gradient of ReLU can either be 0 or 1. If large error gradients accumulate, they can cause the weights to update in large increments, potentially leading to an unstable network. However, ReLU is generally less likely to suffer from vanishing gradients compared to sigmoid since it does not saturate in the positive domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: What is meant by virtual memory?\n",
    "#### Answer\n",
    "Virtual memory is a memory management capability of an operating system (OS) that uses hardware and software to allow a computer to compensate for physical memory shortages, temporarily transferring data from random access memory (RAM) to disk storage. This process creates the illusion to users of a very large (main) memory. It allows systems to handle larger amounts of data than the actual physical RAM present and enables programs to be larger than physical memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: What is Time complexity of insertion in Linked List vs. Array? \n",
    "#### Answer\n",
    "Linked List: The time complexity of inserting a new node in a linked list is O(1) if the position is known (for example, inserting at the head or directly after a given node). If the position is not known and needs to be searched, it becomes O(n), where n is the number of elements in the list.\n",
    "Array: Insertion in an array has a time complexity of O(n) in the worst case, as elements may need to be shifted to make space for the new element, particularly if inserting at the beginning or somewhere in the middle of the array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9:  What filter to use Smoothing an image?\n",
    "#### Answer\n",
    "\n",
    "For smoothing an image, commonly used filters include the Gaussian filter and median filter.\n",
    "\n",
    "Gaussian Filter: Ideal for removing Gaussian noise and is widely used due to its properties of having no overshoot to a step function input while minimizing the rise and fall time. This is achieved by a weighted average of surrounding pixels and has the effect of blurring and reducing detail and noise.\n",
    "\n",
    "Median Filter: Particularly effective at removing 'salt and pepper' or impulse noise. It works by moving through the image pixel by pixel, replacing each value with the median value of neighbouring pixels. The median is calculated by first sorting all the pixel values from the surrounding neighborhood into numerical order and then replacing the pixel being considered with the middle pixel value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10:  In Memory storage -what are heap and stack?\n",
    "#### Answer\n",
    "\n",
    "Heap: The heap is used for dynamic memory allocation, with variables being allocated and de-allocated in any order. Memory in the heap persists until it is freed. Heap space is typically larger than stack space but managing memory allocation and deallocation is more complex due to fragmentation issues.\n",
    "\n",
    "Stack: The stack is used for static memory allocation, which allocates memory in a Last In, First Out (LIFO) order. It is particularly used for storing function call frames, local variables, and return addresses during program execution. This type of memory allocation is efficient because of its organization and has a very fast access time, but it is limited in size and can lead to stack overflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11:  How would I handle different aspect ratio of images?\n",
    "#### Answer\n",
    "The aspect ratio of an image is the ratio of its width to its height. \n",
    "\n",
    "Resizing: A common method is to resize images to a fixed size that the model expects, typically using interpolation methods like bilinear or bicubic interpolation. \n",
    "\n",
    "Padding: To maintain the original aspect ratio without distortion, images can be padded with a border (e.g., zero-padding) to reach the required dimensions. \n",
    "\n",
    "Cropping: Alternatively, images can be cropped to the desired aspect ratio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12: Definition of Precision, Recall, and F1-Score\n",
    "#### Answer\n",
    "Precision: The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "\n",
    "Recall (Sensitivity): The ratio of correctly predicted positive observations to the all observations in actual class\n",
    "\n",
    "F1-Score: The harmonic mean of Precision and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13: How to Do Classification Using Decision Tree\n",
    "#### Answer\n",
    "In Decision Trees, for predicting a class label for a record we start from the root of the tree. We compare the values of the root attribute with the record‚Äôs attribute. On the basis of comparison, we follow the branch corresponding to that value and jump to the next node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14: What are MSE, OLS, MAP?\n",
    "#### Answer\n",
    "MSE (Mean Squared Error): A measure of the average of the squares of the errors‚Äîthat is, the average squared difference between the estimated values and the actual value.\n",
    "\n",
    "OLS (Ordinary Least Squares): A method for estimating the unknown parameters in a linear regression model. OLS chooses the parameters of a linear function of a set of explanatory variables by minimizing the sum of the squares of the differences between the target dependent variable and those predicted by the linear function.\n",
    "\n",
    "MAP (Maximum a Posteriori estimation): An estimate of an unknown quantity, that equals the mode of the posterior distribution. The MAP can be used to obtain a point estimate of an unobserved quantity on the basis of empirical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15: What is A feature descriptor?\n",
    "#### Answer\n",
    "A feature descriptor is the information retrieved from images in the form of numerical values that are challenging for a human to comprehend and correlate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16: Tell about some widely used feature descriptors in computer vision\n",
    "#### Answer\n",
    "\n",
    "SIFT (Scale-Invariant Feature Transform):\n",
    "Captures key points in an image and generates a descriptor based on the image gradient around each key point. SIFT descriptors are invariant to image scale and rotation and provide some robustness to changes in illumination, noise, and minor changes in viewpoint.\n",
    "\n",
    "SURF (Speeded Up Robust Features):\n",
    "Similar to SIFT but faster to compute and more efficient, making it useful for real-time applications. SURF is also scale and rotation invariant and performs well under different lighting conditions.\n",
    "\n",
    "ORB (Oriented FAST and Rotated BRIEF):\n",
    "A very fast binary descriptor based on BRIEF that is rotation invariant and resistant to noise. ORB is often used in real-time applications where computational resources are limited.\n",
    "\n",
    "HOG (Histogram of Oriented Gradients):\n",
    "Describes the distribution of intensity gradients and edge directions in an image. It is particularly effective for human detection in images.\n",
    "\n",
    "LBP (Local Binary Patterns):\n",
    "A simple yet efficient texture descriptor. LBP labels the pixels of an image by thresholding the neighborhood of each pixel with the center value and considers the result as a binary number.For each pixel in an image, LBP compares the pixel value with the values of its neighbors. Typically, a 3x3 neighborhood is used, which means 8 surrounding pixels are compared against the center pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 17: Explain Yolo the object detection techniques\n",
    "#### Answer\n",
    "YOLO Architecture:\n",
    "\n",
    "**1.** __Single Neural Network Pass__: YOLO treats object detection as a single regression problem, taking an image as input and outputting bounding boxes and class probabilities for detected objects in one forward pass through a convolutional neural network (CNN).\n",
    "\n",
    "**2.** Grid Division: The input image is divided into an S√óS grid, where each cell in the grid is responsible for predicting bounding boxes and class probabilities for objects whose center falls within the cell.\n",
    "\n",
    "**3.** __Bounding Boxes__ : Each grid cell predicts multiple bounding boxes, each defined by:\n",
    "\n",
    "(x,y): The coordinates of the box's center, relative to the cell.\n",
    "\n",
    "w,h: The width and height of the box, relative to the image size.\n",
    "\n",
    "**4.** __Confidence Score__: A confidence score indicating the box's accuracy, which combines:\n",
    "The probability that an object is present. The Intersection Over Union (IoU) between the predicted box and the ground truth box.\n",
    "\n",
    "**5.** __Class Probabilities__: For each grid cell, YOLO also predicts class probabilities for the detected objects, representing the likelihood that an object belongs to each of the classes considered by the model.\n",
    "\n",
    "**6.** __Output Structure__: YOLO's output consists of a tensor that encodes bounding boxes, confidence scores, and class probabilities for each grid cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 18: Deep learning model after giving just two images? what's this nonsense??\n",
    "#### Answer\n",
    "Training a deep learning model from only two images is impractical due to insufficient data for learning and generalization. For small datasets, transfer learning and data augmentation can be explored, but typically, larger datasets are required for deep learning to be effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 19: \n",
    "#### Answer\n",
    "The softmax activation function is not suitable for pose estimation tasks because these tasks typically require continuous outputs to represent coordinates or heatmaps. In contrast, softmax outputs a probability distribution best suited for discrete classification problems. For pose estimation, linear activation, heatmap representations, and other approaches more aligned with regression tasks are commonly used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 20: Feature extraction and feature selection differences?\n",
    "#### Answer\n",
    "**Approach:**\n",
    "\n",
    "Feature Extraction: Creates new features from existing ones.\n",
    "\n",
    "Feature Selection: Chooses a subset of the existing features.\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Feature Extraction: Focuses on better representation of data.\n",
    "\n",
    "Feature Selection: Focuses on simplifying the model.\n",
    "\n",
    "**Techniques:**\n",
    "\n",
    "Feature Extraction: Uses transformation techniques like PCA, t-SNE, or custom functions.\n",
    "\n",
    "Feature Selection: Uses filter, wrapper, or embedded methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 21: How much dada is required for transfer learning?\n",
    "#### Answer\n",
    "The amount of data required for transfer learning can vary significantly based on several factors, including the complexity of the problem, the similarity of the new data to the data on which the model was originally trained, and the model architecture. However, transfer learning typically requires much less data than training a model from scratch.\n",
    "\n",
    "***1. Complexity of the Problem***\n",
    "\n",
    "For complex tasks that require extensive feature learning (e.g., image recognition or natural language understanding), more data might be necessary even with transfer learning.\n",
    "\n",
    "***2. Similarity to Pre-trained Data***\n",
    "\n",
    "The more similar the new task is to the original task on which the model was pre-trained, the less data you generally need. For example, if you're fine-tuning a model pre-trained on a large image dataset like ImageNet for a similar classification task, you may only need a few hundred to a few thousand labeled images for effective transfer learning.\n",
    "\n",
    "***3. Model Architecture***\n",
    "\n",
    "Large, complex models typically require more data to fine-tune effectively, while smaller models may generalize well with less data. If you're using a pre-trained model with many layers, you might initially freeze most layers and only fine-tune the later layers to avoid overfitting, especially with smaller datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 22: A depth image is an image that built like a matrix that in each cell there is a number that represents the distance from an object. You have a camera that takes 100 pictures of the same object but the pictures are a bit different because of the materials. Find a simple way to compare between 2 cameras to find which one has less changes between the 100 pictures taken?\n",
    "#### Answer \n",
    "The key idea is to measure the variability of the depth values across the 100 images for each camera. One effective way to measure the variability is by calculating the standard deviation for each pixel across the 100 images. The camera with the lower average standard deviation produces more consistent images, as smaller standard deviation indicates less variation between the images.After calculating the average standard deviation for both cameras, you can conclude which camera has less variability and, therefore, which one produces more stable and consistent depth images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 23: What are the challenges of developing software for embedded systems compared to general-purpose systems?\n",
    "#### Answer \n",
    "1. Memory and Processing Power: Embedded systems often operate with limited memory and processing capabilities. \n",
    "\n",
    "2. Many embedded systems have real-time constraints, where timely responses to events are critical.\n",
    "\n",
    "3. Embedded software is tightly coupled with specific hardware components, such as sensors, actuators, and communication interfaces. Developers must have a deep understanding of the hardware and write low-level code to interact with it directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 24 : What are difference of multiprocessing, concurrent, threats and explain around how to handle multiprocess in python?\n",
    "#### Answer \n",
    "1. Multiprocessing:\n",
    "\n",
    "Multiprocessing involves running multiple processes simultaneously, where each process has its own memory space. This approach allows for parallelism, meaning that tasks can truly run at the same time on multi-core CPUs.The multiprocessing module in Python provides an interface similar to the threading module but uses processes instead of threads. This helps bypass the Global Interpreter Lock (GIL), which limits threads in Python from running truly concurrently. Multiprocessing is useful for CPU-bound tasks that require heavy computation.\n",
    "\n",
    "2. Concurrency:\n",
    "\n",
    "Concurrency refers to the ability to handle multiple tasks simultaneously. It does not necessarily imply parallelism but rather involves dealing with multiple tasks at once, which might include interleaving between tasks.Concurrency in Python is often achieved using threading or asynchronous programming.\n",
    "\n",
    "3. Threading:\n",
    "\n",
    "Threading involves running multiple threads (Threads in Python refer to lightweight, concurrent units of execution within a single process. A thread operates independently, shares the process's memory space, and executes concurrently with other threads within the same process.) within a single process, where threads share the same memory space. This can provide concurrency but not true parallelism due to the GIL in CPython, which ensures only one thread executes Python bytecode at a time. The threading module provides the tools to create and manage threads. Threading is suitable for I/O-bound tasks where the main program might be waiting on external resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 25:  What is an End-to-End Machine Learning Pipeline?\n",
    "#### Answer\n",
    "An end-to-end machine learning pipeline automates machine learning workflow by handling data processing, integration, model creation, evaluation, and delivery. It streamlines the implementation of the model and enhances its flexibility.\n",
    "\n",
    "The fundamental stages in an ML pipeline:\n",
    "\n",
    "Data Preprocessing. \n",
    "Data Cleaning. \n",
    "Feature Engineering.\n",
    "Model Selection.\n",
    "Prediction Generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 26: How do you approach developing a new computer vision algorithm from scratch?\n",
    "#### Answer\n",
    "\n",
    "1. Problem definition\n",
    "\n",
    "2. Data collection and preparation\n",
    "\n",
    "3. Model selection and development\n",
    "\n",
    "4. Training and testing\n",
    "\n",
    "5.  Deployment and maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 27: So, how have you contributed to agile software development teams in the past?\n",
    "#### Answer\n",
    "In my previous roles, I've had the opportunity to work in agile environments where teamwork and flexibility are key. One way I've contributed is by embracing agile ceremonies, such as daily stand-ups, sprint planning, and retrospectives. For example, during stand-ups, I always make sure to communicate any roadblocks I'm facing, as well as share updates on my progress. This helps the team stay aligned and allows us to address issues quickly.\n",
    "\n",
    "**Interviewer**: That sounds helpful. How about during sprint planning? How do you contribute there?\n",
    "\n",
    "**You**: During sprint planning, I focus on thoroughly understanding the user stories and their acceptance criteria. I actively participate in discussions to clarify requirements and help estimate the effort involved. This ensures that the team has a shared understanding of the tasks ahead. I also take on tasks that align with my skills and interests but am flexible enough to pick up other tasks as needed to support the team.\n",
    "\n",
    "**Interviewer**: That's great. How do you handle changes or unexpected challenges during a sprint?\n",
    "\n",
    "**You**: Agile is all about adaptability, so when unexpected challenges arise, I communicate openly with the team and adapt our plans accordingly. For instance, if a new requirement or a blocker comes up, I'll discuss it with the team during our daily stand-up or immediately if it's urgent. This way, we can re-prioritize tasks or find solutions collaboratively. I've found that this flexibility helps us maintain momentum and stay focused on delivering value.\n",
    "\n",
    "**Interviewer**: What about retrospectives? How do you contribute to those?\n",
    "\n",
    "**You**: Retrospectives are valuable for continuous improvement, and I make sure to participate actively by sharing insights and suggestions. For example, if we encountered a specific issue during a sprint, I'll suggest ways we can prevent it in the future or improve our process. I also appreciate hearing feedback from others and work on areas where I can improve. This open dialogue helps our team grow and adapt with each sprint.\n",
    "\n",
    "**Interviewer**: It sounds like you've had a lot of positive experiences with agile teams. What do you find most rewarding about working in agile environments?\n",
    "\n",
    "**You**: I really enjoy the collaboration and continuous learning that come with agile. The ability to quickly respond to change and improve iteratively keeps things dynamic and engaging. I also appreciate the strong focus on delivering customer value, which makes the work feel purposeful. Being part of a team that's aligned, adaptable, and focused on delivering quality software is incredibly rewarding.\n",
    "\n",
    "**Interviewer**: What tools do you use to manage your work in an agile environment?\n",
    "\n",
    "**You**: I've used a variety of tools to manage work in agile settings, depending on the specific needs of the team and organization. One of the most common tools I've used is Jira, which is great for tracking tasks, user stories, and bugs. Jira‚Äôs customizable workflows and powerful reporting features help our team stay organized and aligned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 28: Interviewer: What challenges do you anticipate in developing computer vision solutions for automotive applications?\n",
    "#### Answer\n",
    "\n",
    "You: One of the major challenges in developing computer vision solutions for automotive applications is ensuring reliability under various conditions. Unlike controlled environments, cars encounter diverse situations like varying weather, lighting, and road conditions. The algorithms need to perform consistently, whether it's bright and sunny or raining heavily. Ensuring that the models are robust against such variations is crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 29: Interviewer: How would you integrate multiple sensors, such as cameras and LIDAR, in an automotive application?\n",
    "#### Answer \n",
    "You: Integrating multiple sensors like cameras and LIDAR in an automotive application requires a thoughtful approach to sensor fusion, where the goal is to combine the strengths of each sensor to improve the overall system's performance. The first step is to understand the characteristics of each sensor. Cameras provide rich visual information, which is great for recognizing objects and understanding the environment, while LIDAR provides accurate depth information, useful for mapping and obstacle detection."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
